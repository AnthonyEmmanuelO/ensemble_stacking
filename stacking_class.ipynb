{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Automated Stacking Class\n",
    "\n",
    "In this notebook I'm going to start building a stacking class that can automatically do a few things:\n",
    "- Take in a dictionary of algorithms (hopefully eventually from different libraries like SKLearn, Keras, XGBoost, and LightGBM) and automatically grid search parameters and save the top performing models.\n",
    "- Fit a cross validating stacking meta regressor or classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stacking_ensemble(object):\n",
    "    \n",
    "    def __init__(self, base_models, stacking_model, k_folds=3):\n",
    "        \n",
    "        # 'models' will be a list of base model.\n",
    "        self.base_models = base_models\n",
    "        self.stacking_model = stacking_model\n",
    "        self.k_folds = k_folds\n",
    "        self.top_models_gs = False\n",
    "        self.top_models_non_gs = False\n",
    "        \n",
    "    def find_top_models(self, X, y, k_models=1, cv=None, subsample=None, scoring=None):\n",
    "        \"\"\"\n",
    "        DOCSTRING\n",
    "        \n",
    "        This function will look at the basemodels in, and finds the best models and then saves the best\n",
    "        model/parameter combinations to a new object which can be used for fitting.\n",
    "        \n",
    "        scoring: way of comparing performance of models.  Can take on all values from SKLearn model\n",
    "        evaluation documentation\n",
    "        \n",
    "        subsample: downsample the training data to make model selection faster.  Values between 0 and 1.\n",
    "        \"\"\"\n",
    "\n",
    "        X_data = np.array(X)\n",
    "        y_data = np.array(y)\n",
    "\n",
    "        if subsample:\n",
    "            axes_choices = np.random.binomial(n=1, p=subsample, size=X.shape[0])\n",
    "            X_data = X_data[axes_choices == 1]\n",
    "            y_data = y_data[axes_choices == 1]\n",
    "\n",
    "        best_models = []\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "\n",
    "        model_scores = []\n",
    "        for model in self.base_models.values():\n",
    "            score = np.mean(cross_val_score(model, X_data, y_data, scoring=scoring, cv=cv))\n",
    "            model_scores.append({'model': model, 'score': score})\n",
    "\n",
    "        self.top_models = sorted(model_scores, key=lambda k: k['score'], reverse=True)[:k_models]\n",
    "        self.top_models_non_gs = True\n",
    "        \n",
    "    def find_top_models_gs(self, X, y, k_models=1, cv=None, subsample=None, scoring=None, verbose=0):\n",
    "        \"\"\"\n",
    "        This will find the top models by gridsearching.\n",
    "        \n",
    "        To use this feature, base_models must be initially passed in this form: \n",
    "        \n",
    "        base_models = {'log_reg': {'model': lr,\n",
    "                                   'param_grid': {'penalty': ['l1', 'l2'], 'C': [.5, 1]}},\n",
    "                       'rand_for': {'model': rf, \n",
    "                                    'param_grid': {'max_depth': [2,4,5]}},\n",
    "                        }\n",
    "                \n",
    "        \"\"\"\n",
    "        \n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        \n",
    "        model_scores = []\n",
    "        \n",
    "        X_data = np.array(X)\n",
    "        y_data = np.array(y)\n",
    "\n",
    "        if subsample:\n",
    "            axes_choices = np.random.binomial(n=1, p=subsample, size=X.shape[0])\n",
    "            X_data = X_data[axes_choices == 1]\n",
    "            y_data = y_data[axes_choices == 1]\n",
    "\n",
    "        for model_name, data in self.base_models.items():\n",
    "            \n",
    "            model = data['model']\n",
    "            parameters = data['param_grid']\n",
    "            \n",
    "            gscv = GridSearchCV(model, param_grid=parameters, cv=cv, verbose=verbose)\n",
    "            gscv.fit(X_data, y_data)\n",
    "            \n",
    "            model_scores += ([{'model': model,\n",
    "                   'score': score,\n",
    "                   'parameters': params} for params, score in zip(gscv.cv_results_['params'],\n",
    "                                                               gscv.cv_results_['mean_test_score'])])\n",
    "        \n",
    "        top_models = sorted(model_scores, key=lambda k: k['score'], reverse=True)[:k_models]\n",
    "        self.top_models_gs = True\n",
    "        self.top_models = top_models\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        df_meta = np.zeros(X.shape)\n",
    "        fold_ids = np.zeros(df_meta.shape[0])  \n",
    "        \n",
    "        from sklearn.model_selection import KFold\n",
    "        kf = KFold(n_splits=self.k_folds, shuffle=True)\n",
    "        \n",
    "        for i, (train, test) in enumerate(kf.split(X, y)):\n",
    "            fold_ids[test] = i\n",
    "        \n",
    "        \n",
    "        if not self.top_models_gs and not self.top_models_non_gs:\n",
    "            \n",
    "            print 'fitting base models'    \n",
    "            for k in set(fold_ids):\n",
    "                print '---> Fitting fold ', k + 1\n",
    "                train_fold = X[fold_ids != k, :]\n",
    "                \n",
    "                for i, model in enumerate(self.base_models.values()):\n",
    "                    print '------> Fitting model ', str(i)\n",
    "                    model.fit(train_fold, y[fold_ids != k])\n",
    "                    df_meta[fold_ids == k, i] = model.predict(X[fold_ids == k, :]) \n",
    "                    \n",
    "            # Fit each base model to the entire X training set once we've fit the meta columns\n",
    "            for model in self.base_models.values():\n",
    "                model.fit(X, y)\n",
    "            \n",
    "        else:\n",
    "            # If we've grid searched best models, here we'll fit the parameters to all the models.\n",
    "            if self.top_models_gs:\n",
    "                for model_dict in self.top_models:\n",
    "                    model_dict['model'].set_params(**model_dict['parameters'])\n",
    "            \n",
    "            for k in set(fold_ids):\n",
    "                print '---> Fitting fold ', k + 1\n",
    "                train_fold = X[fold_ids != k, :]\n",
    "                \n",
    "                for i, model_dict in enumerate(self.top_models):\n",
    "                    print '------> Fitting model ', str(i)\n",
    "                    model_dict['model'].fit(train_fold, y[fold_ids != k])\n",
    "                    df_meta[fold_ids == k, i] = model_dict['model'].predict(X[fold_ids == k, :])\n",
    "                    \n",
    "            # Fit each base model to the entire X training set once we've fit the meta columns\n",
    "            for model_dict in self.top_models:\n",
    "                model_dict['model'].fit(X, y)                \n",
    "         \n",
    "        # FITTING THE FINAL META MODEL\n",
    "        print 'fitting stacking model...'\n",
    "        self.stacking_model.fit(df_meta, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        test_meta = np.zeros(X.shape)\n",
    "        \n",
    "        if not self.top_models_gs and not self.top_models_non_gs:\n",
    "            for i, model in enumerate(self.base_models.values()):\n",
    "                test_meta[:, i] = model.predict(X)\n",
    "        else:\n",
    "            for i, model_dict in enumerate(self.top_models):\n",
    "                test_meta[:, i] = model_dict['model'].predict(X)\n",
    "        predictions = self.stacking_model.predict(test_meta)\n",
    "        return predictions\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        return accuracy_score(y, predictions)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=50, n_jobs=1, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False),\n",
       "  'parameters': {'max_depth': 2},\n",
       "  'score': 0.94285714285714284},\n",
       " {'model': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=50, n_jobs=1, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False),\n",
       "  'parameters': {'max_depth': 5},\n",
       "  'score': 0.94285714285714284},\n",
       " {'model': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False),\n",
       "  'parameters': {'C': 0.5, 'penalty': 'l1'},\n",
       "  'score': 0.94285714285714284},\n",
       " {'model': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False),\n",
       "  'parameters': {'C': 0.5, 'penalty': 'l2'},\n",
       "  'score': 0.94285714285714284}]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "X = iris_data.data\n",
    "y = iris_data.target\n",
    "\n",
    "lr = LogisticRegression()\n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=2)\n",
    "\n",
    "base_models = {'log_reg': {'model': lr, 'param_grid': {'penalty': ['l1', 'l2'], 'C': [.5, 1]}},\n",
    "                'rand_for': {'model': rf, 'param_grid': {'max_depth': [2,4,5]}\n",
    "                }}\n",
    "\n",
    "stacker = stacking_ensemble(base_models, stacking_model=gbc)\n",
    "stacker.find_top_models_gs(X, y, k_models=4, cv=5, subsample=.5, scoring='r2', verbose=1)\n",
    "stacker.top_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting base models\n",
      "---> Fitting fold  1.0\n",
      "------> Fitting model  0\n",
      "------> Fitting model  1\n",
      "------> Fitting model  2\n",
      "------> Fitting model  3\n",
      "---> Fitting fold  2.0\n",
      "------> Fitting model  0\n",
      "------> Fitting model  1\n",
      "------> Fitting model  2\n",
      "------> Fitting model  3\n",
      "---> Fitting fold  3.0\n",
      "------> Fitting model  0\n",
      "------> Fitting model  1\n",
      "------> Fitting model  2\n",
      "------> Fitting model  3\n",
      "fitting stacking model\n"
     ]
    }
   ],
   "source": [
    "stacker.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "1. base models can't be passed in as a dict because order won't be maintained\n",
    "    1. maybe what we can do is allow you to pass in basemodels as a list of dictionaries, and then reformat so that it's the same as the way we're currently storing the top_models (this already is a list of dictionaries).\n",
    "2. If there's no parameters you should just be able to pass the models in as a list.\n",
    "3. For grid searching parameters, we could make it like gridsearching in a pipeline is currently, and then internally it parses the dictionary and creates a new parameters dictionary that can be used for models later.\n",
    "    1. Could also just make it so that you pass in the models as a list, and then pass in the parameters as a list of dictionaries, and you just have to maintain the order so they can be zipped together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
