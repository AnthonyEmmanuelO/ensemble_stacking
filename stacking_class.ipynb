{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Automated Stacking Class\n",
    "\n",
    "In this notebook I'm going to start building a stacking class that can automatically do a few things:\n",
    "- Take in a dictionary of algorithms (hopefully eventually from different libraries like SKLearn, Keras, XGBoost, and LightGBM) and automatically grid search parameters and save the top performing models.\n",
    "- Fit a cross validating stacking meta regressor or classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stacking_ensemble(object):\n",
    "    \n",
    "    def __init__(self, base_models, stacking_model, k_folds=3, parameter_grids=None):\n",
    "        \n",
    "        # 'models' will be a list of base model.\n",
    "        self.base_models = base_models\n",
    "        self.stacking_model = stacking_model\n",
    "        self.k_folds = k_folds\n",
    "        \n",
    "        # Booleans for telling if the top model functions have been used\n",
    "        self.top_models_gs = False\n",
    "        self.top_models_non_gs = False\n",
    "        \n",
    "        self.parameter_grids = parameter_grids\n",
    "        \n",
    "    def find_top_models(self, X, y, k_models=1, cv=None, subsample=None, scoring=None):\n",
    "        \"\"\"\n",
    "        DOCSTRING\n",
    "        \n",
    "        This function will look at the basemodels in, and finds the best models and then saves the best\n",
    "        model/parameter combinations to a new object which can be used for fitting.\n",
    "        \n",
    "        scoring: way of comparing performance of models.  Can take on all values from SKLearn model\n",
    "        evaluation documentation\n",
    "        \n",
    "        subsample: downsample the training data to make model selection faster.  Values between 0 and 1.\n",
    "        \"\"\"\n",
    "\n",
    "        X_data = np.array(X)\n",
    "        y_data = np.array(y)\n",
    "\n",
    "        if subsample:\n",
    "            axes_choices = np.random.binomial(n=1, p=subsample, size=X.shape[0])\n",
    "            X_data = X_data[axes_choices == 1]\n",
    "            y_data = y_data[axes_choices == 1]\n",
    "\n",
    "        best_models = []\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "\n",
    "        model_scores = []\n",
    "        for model in self.base_models:\n",
    "            score = np.mean(cross_val_score(model, X_data, y_data, scoring=scoring, cv=cv))\n",
    "            model_scores.append({'model': model, 'score': score})\n",
    "\n",
    "        self.top_models = sorted(model_scores, key=lambda k: k['score'], reverse=True)[:k_models]\n",
    "        self.top_models_non_gs = True\n",
    "        \n",
    "    def find_top_models_gs(self, X, y, k_models=1, cv=None, parameter_grids=None, subsample=None,\n",
    "                           scoring=None, verbose=0):\n",
    "        \"\"\"\n",
    "        This will find the top models by gridsearching.\n",
    "        \n",
    "        To use this feature, base_models and parameter grids must be passed in the same order\n",
    "        Parameter grids need to be a list of dictionaries of sklearn parameters\n",
    "                \n",
    "        \"\"\"\n",
    "        # set class variable parameter grids to this function's version if it hasn't been set yet or this one is passed\n",
    "        if not self.parameter_grids or parameter_grids:\n",
    "            self.parameter_grids = parameter_grids\n",
    "        \n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        \n",
    "        model_scores = []\n",
    "        \n",
    "        X_data = np.array(X)\n",
    "        y_data = np.array(y)\n",
    "\n",
    "        if subsample:\n",
    "            axes_choices = np.random.binomial(n=1, p=subsample, size=X.shape[0])\n",
    "            X_data = X_data[axes_choices == 1]\n",
    "            y_data = y_data[axes_choices == 1]\n",
    "\n",
    "        for model, parameters in zip(self.base_models, self.parameter_grids):\n",
    "            \n",
    "            gscv = GridSearchCV(model, param_grid=parameters, cv=cv, verbose=verbose)\n",
    "            gscv.fit(X_data, y_data)\n",
    "            \n",
    "            model_scores += ([{'model': model,\n",
    "                   'score': score,\n",
    "                   'parameters': params} for params, score in zip(gscv.cv_results_['params'],\n",
    "                                                               gscv.cv_results_['mean_test_score'])])\n",
    "        \n",
    "        self.top_models = sorted(model_scores, key=lambda k: k['score'], reverse=True)[:k_models]\n",
    "        self.top_models_gs = True\n",
    "\n",
    "    def fit(self, X, y, use_top=True):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        df_meta = np.zeros(X.shape)\n",
    "        fold_ids = np.zeros(df_meta.shape[0])  \n",
    "        \n",
    "        from sklearn.model_selection import KFold\n",
    "        kf = KFold(n_splits=self.k_folds, shuffle=True)\n",
    "        \n",
    "        for i, (train, test) in enumerate(kf.split(X, y)):\n",
    "            fold_ids[test] = i\n",
    "        \n",
    "        \n",
    "        if (not self.top_models_gs and not self.top_models_non_gs) or not use_top:\n",
    "            \n",
    "            print 'fitting base models'    \n",
    "            for k in set(fold_ids):\n",
    "                print '---> Fitting fold ', k + 1\n",
    "                train_fold = X[fold_ids != k, :]\n",
    "                \n",
    "                for i, model in enumerate(self.base_models):\n",
    "                    print '------> Fitting model ', str(i)\n",
    "                    model.fit(train_fold, y[fold_ids != k])\n",
    "                    df_meta[fold_ids == k, i] = model.predict(X[fold_ids == k, :]) \n",
    "                    \n",
    "            # Fit each base model to the entire X training set once we've fit the meta columns\n",
    "            for model in self.base_models:\n",
    "                model.fit(X, y)\n",
    "            \n",
    "        else:\n",
    "            # If we've grid searched best models, here we'll fit the parameters to all the models.\n",
    "            if self.top_models_gs:\n",
    "                for model_dict in self.top_models:\n",
    "                    model_dict['model'].set_params(**model_dict['parameters'])\n",
    "            \n",
    "            for k in set(fold_ids):\n",
    "                print '---> Fitting fold ', k + 1\n",
    "                train_fold = X[fold_ids != k, :]\n",
    "                \n",
    "                for i, model_dict in enumerate(self.top_models):\n",
    "                    print '------> Fitting model ', str(i)\n",
    "                    model_dict['model'].fit(train_fold, y[fold_ids != k])\n",
    "                    df_meta[fold_ids == k, i] = model_dict['model'].predict(X[fold_ids == k, :])\n",
    "                    \n",
    "            # Fit each base model to the entire X training set once we've fit the meta columns\n",
    "            for model_dict in self.top_models:\n",
    "                model_dict['model'].fit(X, y)                \n",
    "         \n",
    "        # FITTING THE FINAL META MODEL\n",
    "        print 'fitting stacking model...'\n",
    "        self.stacking_model.fit(df_meta, y)\n",
    "        print 'done!'\n",
    "        \n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        test_meta = np.zeros(X.shape)\n",
    "        \n",
    "        if not self.top_models_gs and not self.top_models_non_gs:\n",
    "            for i, model in enumerate(self.base_models):\n",
    "                test_meta[:, i] = model.predict(X)\n",
    "        else:\n",
    "            for i, model_dict in enumerate(self.top_models):\n",
    "                test_meta[:, i] = model_dict['model'].predict(X)\n",
    "        predictions = self.stacking_model.predict(test_meta)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Fitting fold  1.0\n",
      "------> Fitting model  0\n",
      "------> Fitting model  1\n",
      "------> Fitting model  2\n",
      "------> Fitting model  3\n",
      "---> Fitting fold  2.0\n",
      "------> Fitting model  0\n",
      "------> Fitting model  1\n",
      "------> Fitting model  2\n",
      "------> Fitting model  3\n",
      "---> Fitting fold  3.0\n",
      "------> Fitting model  0\n",
      "------> Fitting model  1\n",
      "------> Fitting model  2\n",
      "------> Fitting model  3\n",
      "fitting stacking model...\n",
      "done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "X = iris_data.data\n",
    "y = iris_data.target\n",
    "\n",
    "lr = LogisticRegression()\n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=2)\n",
    "gbc = GradientBoostingClassifier(n_estimators=20, max_depth=3)\n",
    "\n",
    "base_models = [lr, rf]\n",
    "\n",
    "params = [{'penalty': ['l1', 'l2'], 'C': [.5, 1]},\n",
    "         {'max_depth': [2,4,5]}]\n",
    "\n",
    "# Example of using the find top models by gridsearching and then fitting.\n",
    "\n",
    "stacker = stacking_ensemble(base_models, stacking_model=gbc, parameter_grids=params)\n",
    "stacker.find_top_models_gs(X, y, k_models=4, cv=3, subsample=.5, verbose=1)\n",
    "stacker.fit(X, y)\n",
    "stacker.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting base models\n",
      "---> Fitting fold  1.0\n",
      "------> Fitting model  0\n",
      "------> Fitting model  1\n",
      "---> Fitting fold  2.0\n",
      "------> Fitting model  0\n",
      "------> Fitting model  1\n",
      "---> Fitting fold  3.0\n",
      "------> Fitting model  0\n",
      "------> Fitting model  1\n",
      "fitting stacking model...\n",
      "done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacker = stacking_ensemble(base_models, stacking_model=gbc)\n",
    "stacker.find_top_models(X, y, k_models=1, cv=3, subsample=1)\n",
    "stacker.fit(X, y, use_top=False)\n",
    "stacker.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting base models\n",
      "---> Fitting fold  1.0\n",
      "------> Fitting model  0\n",
      "------> Fitting model  1\n",
      "---> Fitting fold  2.0\n",
      "------> Fitting model  0\n",
      "------> Fitting model  1\n",
      "---> Fitting fold  3.0\n",
      "------> Fitting model  0\n",
      "------> Fitting model  1\n",
      "fitting stacking model...\n",
      "done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacker = stacking_ensemble(base_models, stacking_model=gbc)\n",
    "stacker.fit(X, y)\n",
    "stacker.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "1. base models can't be passed in as a dict because order won't be maintained\n",
    "    1. maybe what we can do is allow you to pass in basemodels as a list of dictionaries, and then reformat so that it's the same as the way we're currently storing the top_models (this already is a list of dictionaries).\n",
    "2. If there's no parameters you should just be able to pass the models in as a list.\n",
    "4. It'd be nice to add in the capacity to grid search the final classifier and then use the top performing parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
